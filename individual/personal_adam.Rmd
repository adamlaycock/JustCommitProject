---
title: "Adam Personal Investigation"
author: "AdamLaycock"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-lib, message = FALSE}
library(tidyverse)
library(janitor)
library(workflows)
library(parsnip)
library(tidyclust)
library(tidymodels)
library(usmap)
library(gghighlight)
```

# Load & Clean Data

```{r load-data}
details = read_rds('../data/clean_data/details_clean.rds')
fatalities = read_rds('../data/clean_data/fatalities_clean.rds')
```

# Damage by Event Type

```{r}
cost_data <- details %>% 
  select(
    event_type, damage_property, damage_crops
  ) %>% 
    group_by(
      event_type
    ) %>% 
      summarise(
        Property = sum(damage_property, na.rm=TRUE),
        Crops = sum(damage_crops, na.rm=TRUE)
      ) %>%
        slice_max(
          order_by = Property + Crops, 
          n = 20
        ) %>% 
          pivot_longer(cols=c('Property', 'Crops'),
                      names_to='type',
                      values_to='damage'
          )

damage_plot <- cost_data %>% 
  ggplot(
    mapping=aes(
      x=damage/sum(damage)*100,
      y=reorder(event_type, damage),
      fill=type
    )
  ) +
  geom_col() +
  labs(title = 'Damage by Storm Event Type between 1996 & 2023', 
       subtitle = 'Total Damage (Property + Crops) was $227bn',
       y = 'Type of Event',
       x = 'Pecentage of Total Damage',
       fill='Damage Type',
       caption='Only the 20 most damaging event types are shown.'
  ) +
  theme_minimal() +
  theme(plot.caption = element_text(hjust = -0.75, face= "italic"))

#ggsave('plots/Damage by Event Type.jpg', plot=damage_plot)
```

# Simple Statistics Function 

```{r Simple Damage Statistics}
eval_percentage_criteria <- function(col, type) {
  col <- sym(col)
  
  if (type == 'event') {
    total <- details %>% 
      nrow()
  
    criteria_total <- details %>% 
      filter(
        !!col > 0
      ) %>%
        nrow()
    
    print('Percentage fulfilling criteria by event: ')
    print(criteria_total / total * 100)
  }
  
  else if (type == 'episode') {
    total <- details %>% 
      group_by(
        episode_id
      ) %>% 
        summarise(
          total = sum(!!col)
        ) %>% 
          nrow()
    
    criteria_total <- details %>% 
      group_by(
        episode_id
      ) %>% 
        summarise(
          total = sum(!!col)
        ) %>% 
          filter(
            total > 0
          ) %>%
            nrow()
    
    print('Percentage fulfilling criteria by episode: ')
    print(criteria_total / total * 100)
  }
    
  else {
    stop("Type must be one of 'event' or 'episode'")
  }
}
```

# K-means Clustering Using Casualties & Damage

```{r Combined Metrics by Event ID}
# Create combined metrics by combining direct and indirect
details <- details %>% 
  mutate(
    attributed_deaths = deaths_direct + deaths_indirect,
    attributed_injuries = injuries_direct + injuries_indirect,
    attributed_casualties = attributed_deaths + attributed_injuries
  )
```

```{r Feature Selection & Engineering}
# Select only relevant data and remove rows with NA
model_data <- details %>% 
  select(
    event_id, attributed_casualties, damage_total, event_type
  ) %>% 
    filter(
      !is.na(damage_total) & !is.na(attributed_casualties)
    )

# Z-Score normalise the data
model_data_scaled <- model_data %>%
  mutate(
    damage_total = as.vector(scale(damage_total)),
    attributed_casualties = as.vector(scale(attributed_casualties))
  )
```

```{r Elbow Plot for Optimisation, eval=FALSE}
# Initialise empty lists
k_list = list()
sse_list = list()

# Loop through 1-30 clusters and store total sum of squared error
for (k in 1:30) {
  kmeans_spec <- k_means(num_clusters = k)
  
  kmeans_fit <- kmeans_spec %>%
    fit(~ damage_total + attributed_casualties, data = model_data_scaled)
  
  kmeans_result <- kmeans_fit$fit
  sse <- kmeans_result$tot.withinss
  
  k_list <- c(k_list, k)
  sse_list <- c(sse_list, sse)
  
  print(paste("Number of clusters:", k))
  print(paste("Total SSE:", sse))
}

# Convert lists to a DataFrame
elbow_data <- data.frame(unlist(k_list), unlist(sse_list))
names(elbow_data) = c("k","total_sse")


# Create elbow plot using clustering data
elbow_data %>% 
  ggplot(
    mapping=aes(
      x=k,
      y=total_sse
    )
  ) + 
  geom_line() +
  geom_point() + 
  scale_x_continuous(breaks = seq(1, 30, by = 1)) +
  labs(
    title='Total SSE by Number of Clusters', 
    x='Number of Clusters (k)',
    y='Total SSE'
  ) +
  theme_minimal()
```

```{r Optimised Model}
kmeans_spec <- k_means(num_clusters = 3)

kmeans_fit <- kmeans_spec %>%
  fit(~ damage_total + attributed_casualties, data = model_data_scaled)

model_data_scaled <- kmeans_fit %>% 
  augment(model_data_scaled)
```

```{r Scatter Plot of Scaled Data by Cluster}
model_data_scaled %>%
  ungroup() %>% 
    ggplot(
      mapping=aes(
        x=damage_total,
        y=attributed_casualties,
        colour=.pred_cluster
      )
    ) +
    geom_jitter() +
    labs(
      x='Scaled Total Damage',
      y='Scaled Attributed Deaths',
      title='K-Means Clustering of Casualties & Damages',
      colour='Cluster'
    ) +
    theme_minimal()
```

```{r Cluster Frequency Table}
model_data_scaled %>% 
  group_by(
    .pred_cluster
  ) %>% 
    summarise(
      total = n()
    )
```

# Change in Event Types Over Time

```{r Total Events by Type & Year}
event_data <- details %>% 
  select(
    begin_dt, event_type
  ) %>% 
    group_by(
      event_type, year(begin_dt)
    ) %>%
      summarise(
        total = n()
      ) %>% 
        arrange(
          desc(total)
        ) %>% 
          rename(
            year = `year(begin_dt)`
          )
```

```{r Scaled Largest Changes, eval=FALSE}
max_range <- event_data %>%
  group_by(
    event_type
  ) %>%
    summarise(
      range_total = (max(total) - min(total)) / mean(total),
      .groups = 'drop'
    ) %>%
      slice_max(
        order_by = abs(range_total), 
        n = 5
      ) 

mr_events <- unique(max_range$event_type)

event_data %>% 
  filter(
    event_type %in% mr_events
  ) %>% 
    group_by(
      event_type
    ) %>% 
      mutate(
        mean_total = mean(total)
      ) %>% 
        ggplot(mapping = aes(
          x = year,
          y = log(total),
          colour = reorder(event_type, desc(mean_total))
        )) + 
        geom_smooth(method = 'gam', se = FALSE) +
        scale_x_continuous(breaks = seq(1996, 2023, by = 2)) +
        labs(
          x = 'Year',
          y = 'Total Events',
          title = 'Number of Events per Year by Event Type',
          subtitle = 'Only events with the five largest ranges of events per year are shown',
          colour = 'Event Type'
        ) +
        theme_minimal()
```

# Geospatial Correlations Between Total Events & Time by Event Type

```{r Map Correlations Between Number of Events & Time}
map_correlations <- function(event_type) {
  event_type_expr <- enquo(event_type)
  
total_region_data <- details %>%
  select(
    begin_dt, event_type, region
  ) %>% 
    group_by(
      region, year(begin_dt)
    ) %>%
      summarise(
        ov_total = n()
      ) %>% 
        rename(
          year = `year(begin_dt)`
        )

  region_data <- details %>%
    filter(
      event_type == !!event_type_expr
    ) %>% 
      select(
        begin_dt, event_type, region
      ) %>% 
        group_by(
          region, year(begin_dt)
        ) %>%
          summarise(
            total = n()
          ) %>% 
            arrange(
              desc(total)
            ) %>% 
              rename(
                year = `year(begin_dt)`
              ) %>% 
                inner_join(
                  total_region_data, by=c('region', 'year')
                ) %>% 
                  mutate(
                    prop = total / ov_total
                  )

  correlation_data <- region_data %>%
    group_by(
      region
    ) %>%
      summarise(
        corr_test = list(tryCatch(
          cor.test(
            year, 
            prop, 
            method = "pearson", 
            use = "complete.obs"
          ), 
          error = function(e) NULL
        ))
      ) %>%
        mutate(
          corr = sapply(corr_test, function(test) if (!is.null(test)) test$estimate else NA),
          p_value = sapply(corr_test, function(test) if (!is.null(test)) test$p.value else NA)
        ) %>%
          filter(
            !is.na(corr) & !is.na(p_value) & p_value <= 0.05
          ) %>%
            select(
              region, corr, p_value
            ) %>%
              mutate(
                event_type = event_type
              )
  
  map_data <- usmap::us_map(regions = "states")
  
  map_data <- map_data %>% 
    mutate(
      full = tolower(full)
    ) %>% 
      rename(
        region = full
      )
  
  correlation_data <- correlation_data %>% 
    mutate(
      region = tolower(region)
    )
  
  data <- left_join(map_data, correlation_data, by='region')
  
  plot_usmap(
    data=data, 
    values='corr'
  ) +
  scale_fill_continuous(name = "Correlation \nCoefficient") +
  theme(legend.position = "right") +
  labs(
    title=paste('Correlations Between Year &', event_type, 'Events as a Proportion of Total State Events'
          ),
    subtitle = 'Only statistically significant (p<=0.05) correlation coefficients are shown'
  )
}

map_correlations('Flash Flood')
```

