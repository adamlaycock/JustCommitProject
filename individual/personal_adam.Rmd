---
title: "Adam Personal Investigation"
author: "AdamLaycock"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-lib, message = FALSE}
library(tidyverse)
library(janitor)
library(workflows)
library(parsnip)
library(tidyclust)
library(tidymodels)
```

# Load & Clean Data

```{r load-data}
details = read_rds('../data/clean_data/details_clean.rds')
fatalities = read_rds('../data/clean_data/fatalities_clean.rds')
```

# K-means Clustering Using Casualties & Damage

```{r Combined Metrics by Event ID, eval=FALSE}
# Create combined metrics by combining direct and indirect
details <- details %>% 
  mutate(
    attributed_deaths = deaths_direct + deaths_indirect,
    attributed_injuries = injuries_direct + injuries_indirect,
    attributed_casualties = attributed_deaths + attributed_injuries
  )
```

```{r Feature Selection & Engineering, eval=FALSE}
# Select only relevant data and remove rows with NA
model_data <- details %>% 
  select(
    event_id, attributed_casualties, damage_total, event_type
  ) %>% 
    filter(
      !is.na(damage_total) & !is.na(attributed_casualties)
    )

# Z-Score normalise the data
model_data_scaled <- model_data %>%
  mutate(
    damage_total = as.vector(scale(damage_total)),
    attributed_casualties = as.vector(scale(attributed_casualties))
  )
```

```{r Elbow Plot for Optimisation, eval=FALSE}
# Initialise empty lists
k_list = list()
sse_list = list()

# Loop through 1-30 clusters and store total sum of squared error
for (k in 1:30) {
  kmeans_spec <- k_means(num_clusters = k)
  
  kmeans_fit <- kmeans_spec %>%
    fit(~ damage_total + attributed_casualties, data = model_data_scaled)
  
  kmeans_result <- kmeans_fit$fit
  sse <- kmeans_result$tot.withinss
  
  k_list <- c(k_list, k)
  sse_list <- c(sse_list, sse)
  
  print(paste("Number of clusters:", k))
  print(paste("Total SSE:", sse))
}

# Convert lists to a DataFrame
elbow_data <- data.frame(unlist(k_list), unlist(sse_list))
names(elbow_data) = c("k","total_sse")


# Create elbow plot using clustering data
elbow_data %>% 
  ggplot(
    mapping=aes(
      x=k,
      y=total_sse
    )
  ) + 
  geom_line() +
  geom_point() + 
  scale_x_continuous(breaks = seq(1, 30, by = 1)) +
  labs(
    title='Total SSE by Number of Clusters', 
    x='Number of Clusters (k)',
    y='Total SSE'
  ) +
  theme_minimal()
```

```{r Optimised Model, eval=FALSE}
kmeans_spec <- k_means(num_clusters = 3)

kmeans_fit <- kmeans_spec %>%
  fit(~ damage_total + attributed_casualties, data = model_data_scaled)

model_data_scaled <- kmeans_fit %>% 
  augment(model_data_scaled)
```

```{r Scatter Plot of Scaled Data by Cluster, eval=FALSE}
model_data_scaled %>% 
  ggplot(
    mapping=aes(
      x=damage_total,
      y=attributed_casualties,
      colour=.pred_cluster
    )
  ) +
  geom_jitter() +
  labs(
    x='Scaled Total Damage',
    y='Scaled Attributed Deaths',
    title='K-Means Clustering of Casualties & Damages',
    colour='Cluster'
  ) +
  theme_minimal()
```

```{r Cluster Frequency Table, eval=FALSE}
model_data_scaled %>% 
  group_by(
    .pred_cluster
  ) %>% 
    summarise(
      total = n()
    )
```

# Change in Event Types Over Time

```{r}
event_data <- details %>% 
  select(
    begin_dt, event_type
  ) %>% 
    group_by(
      event_type, year(begin_dt)
    ) %>%
      summarise(
        total = n()
      ) %>% 
        arrange(
          desc(total)
        ) %>% 
          rename(
            year = `year(begin_dt)`
          )
```

```{r}
max_range <- event_data %>%
  group_by(
    event_type
  ) %>%
    summarise(
      range_total = max(total) - min(total),
      .groups = 'drop'
    ) %>%
      slice_max(
        order_by = abs(range_total), 
        n = 10
      ) 

mr_events <- unique(max_range$event_type)

event_data %>% 
  filter(
    event_type %in% mr_events
  ) %>% 
    group_by(
      event_type
    ) %>% 
      mutate(
        mean_total = mean(total)
      ) %>% 
        ggplot(mapping = aes(
          x = year,
          y = total,
          colour = reorder(event_type, desc(mean_total))
        )) + 
        geom_smooth(method = 'gam', se = FALSE) +
        scale_x_continuous(breaks = seq(1996, 2023, by = 2)) +
        labs(
          x = 'Year',
          y = 'Total Events',
          title = 'Number of Events per Year by Event Type',
          subtitle = 'Only events with the five largest ranges of events per year are shown',
          colour = 'Event Type'
        ) +
        theme_minimal()
```

```{r}

get_correlations <- function(event_type) {
  region_data <- details %>%
    filter(
      event_type == event_type
    ) %>% 
      select(
        begin_dt, event_type, region
      ) %>% 
        group_by(
          region, year(begin_dt)
        ) %>%
          summarise(
            total = n()
          ) %>% 
            arrange(
              desc(total)
            ) %>% 
              rename(
                year = `year(begin_dt)`
              )

  correlation_data <- region_data %>% 
    group_by(
      region
    ) %>% 
      summarise(
        corr = cor(year, total, method = "pearson")
      ) %>% 
        mutate(
          event_type = event_type
        )
  
    return(correlation_data)
}

test <- get_correlations('Hail')
test <- test %>% 
      mutate(
        region = tolower(region)
      )
             
usa_map <- map_data("state")     
             
full_df <- test %>% 
  inner_join(usa_map)
```

```{r}
library(ggplot2)
library(maps)


# Plot the map
full_df %>% 
  ggplot(
    mapping = aes(
      x = long, y = lat, group = group, fill = corr, color = "black"
    )
  ) +
  geom_polygon() +
  labs(title = "Map of the USA") +
  theme_minimal()
```

